{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 浅析最强RNN可微分神经计算机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络在广泛的模式识别任务中表现良好。RNN可以以通过将“word states”转换为记忆向量处理诸如翻译，手写生成和语音识别之类的序列建模任务。但是在实践中RNN及主要变种LSTM处理长距离依赖序列需要大量的计算资源，且效果欠佳。理效果欠佳。为了解决这个问题，多种具有外存储机制的神经网络被设计出来，目前最具知名度的是Deepmind 的Differentiable Neural Computer (DNC) 。\n",
    "\n",
    "通过把神经网络和可读写的外部存储器进行结合，可微分神经计算机（Differentiable Neural Computer，DNC）这种混合学习型神经网络，既能像神经网络那样进行学习，又能像计算机那样处理复杂数据。在发表于Nature的论文中，DNC是一种具有外存储器（不可训练）的特殊的循环神经网络。在每时间步t由可训练的控制器基于t-1 时刻的信息流与外存储器交换信息流之后线性输出预测。\n",
    "\n",
    "![](NTM结构图1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNC使用向量(Vector)来存储记忆。存储器矩阵(Memory\\ matrix)的每行对应于不同的记忆。通过使用控制器通过使用接口向量(Interface \\ parameters)控制一个写头和多个读头（每个读头都是由两种寻址机制线性组合而成，读头数量在结构设计中未有约束）与外存储记忆交互。记忆矩阵$M \\in \\mathbb{R}^{N \\times W} $一行W列表示一组记忆，N行表示记忆矩阵最多可以同时记忆多少组记忆。每个时间步DNC接受上一时刻读头信息流与此时刻信息流组成外部输入信息流（也就是传统LSTM对应每步外部输入input），经过处理发出隐藏状态，隐藏状态生成输出向量和接口向量。接口向量控制读写头与外存储矩阵交互，生成此时刻的写信息，并更新矩阵获得此时刻的读信息。读信息与输出向量线性组合生成此时刻最终输出向量。更新外存储器\n",
    "\n",
    "$$\n",
    "M_t = M_{t-1} \\circ (E-\\mathbf{w}_t^w \\mathbf{e}_t^\\intercal) + \\mathbf{w}_t^w \\mathbf{v}_t^\\intercal\\\\\n",
    "r_t^i = M_t^T w_t^{r,i}\n",
    "$$\n",
    "其中$E \\in \\mathbb{R}^{N \\times W}$为全1矩阵；$w \\in \\mathbb{R}^N$为写头是归一化的分布权重；$\\mathbf{e} \\in \\mathbb{R}^W$为擦除向量，取值局限于[0,1]之间；$\\mathbf{v} \\in \\mathbb{R}^W$为写入记忆向量也就是此时刻新的记忆信息；注意读写头控制变量为记忆矩阵行与行之间的相对强度，而不是具体的记忆信息向量。从左向右，先擦除后写入。在此时刻记忆矩阵更新之后，读头提取此时刻记忆矩阵读头信息流$r_t$，该信息流线性组合此时刻最终输出并且作为下一时刻输入外部输入使用。\n",
    "![](DNC_cell.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较直观的看发表在Nature上的DNC相当于对LSTM添加一个外存储器，提高LSTM的记忆遗忘的问题。这篇论文里面构建了一个非常流畅的可微分的外记忆读写系统。如下图，在时间步t，control接收input vector $x_t$ 和上一个时间步记忆读取向量（读头$r_{t-1}$）以及control(LSTM的隐藏状态矩阵)进行计算处理之后，发出两个向量(ouput vector $v_t$  & interface vector $\\xi_t$)。 其中$v_t$与读头$r_t$线性组合为最终输出向量$y_t$ 。$\\xi_t$ 通过寻址机制Memory Addressing 与记忆矩阵$M$交互生成输出读头记忆$r_t$。\n",
    "\n",
    "![](dnc_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "control 通过发出接口向量控制access中write weighting 和read weightings的更新来控制记忆矩阵并得到读头读取的外部记忆向量。写头控制write weighting通过基于余弦相似性的内容寻址和基于写入频率和时间的使用情况usage确定记忆矩阵行位置的使用情况（根据先后写入和读取频率的程度信息决定被新记忆覆盖的顺序）。读头控制read weighting 通过基于余弦相似性的内容寻址和记忆矩阵行之间相对写入顺序更新读头控制。如下图，每时间步t，control接受上一时刻t-1读头记忆向量和此时刻外部输入作为时刻t的控制器输入信息流，在计算之后发出interface vector 控制外存储器更新写头，由写头控制擦除和写入更新记忆过程（图中绿色操作）。之后新的读头基于新记忆矩阵得到时刻t的读取记忆向量。时刻t得到读取记忆向量同控制器输出向量线性变换映射为时刻t的输出，并且读取记忆向量作为新的短期记忆传递向下一时刻t+1。DNC最终输出结果由时刻t得到读取记忆向量同控制器输出向量线性组合得到，类似于人脑的长期记忆和短期记忆Search of Associative Memory 模型，也就是每时间步的输出由短期记忆和长期记忆线性组合生成。\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_t = \\mathcal{u}_t + W_r [\\mathbf{r}_t^1; \\ldots ;\\mathbf{r}_t^R]\n",
    "$$\n",
    "![](DNC_cell.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附录：\n",
    "\n",
    "### Controller\n",
    "\n",
    "论文使用一个标准的LSTM模型。注意将工业界用的的LSTM公式组去掉batch_size，并设置hidden_num=1即为如下公式组书写形式。\n",
    "$$\n",
    "i_t^l = \\sigma(W_i^l[\\chi_t;h_{t-1}^l;h_t^{l-1}] + b_i^l)\\\\\n",
    "f_t^l = \\sigma(W_f^l[\\chi_t;h_{t-1}^l;h_t^{l-1}] + b_f^l)\\\\\n",
    "s_t^l = f_t^l s_{t-1}^l + i_t^l tanh (W_s^l[\\chi_t;h_{t-1}^l;h_t^{l-1}] + b_s^l) \\\\\n",
    "o_t^l = \\sigma(W_o^l[\\chi_t;h_{t-1}^l;h_t^{l-1}] + b_o^l)\\\\\n",
    "h_t^l = o_t^ltanh(s_t^l)\\\\\n",
    "\\chi_t = [x_t;r_{t-1}^1;...;r_{t-1}^l]\n",
    "$$\n",
    "\n",
    "多层LSTM之间信息流动方向如下图：\n",
    "![](Controller.jpg)\n",
    "\n",
    "每时间步control最终输出的output \\ vector 和interface vector 综合所有隐藏状态向量生成。\n",
    "$$\n",
    "\\nu_t = W_y[h_t^l;...;h_t^l]\\\\\n",
    "\\varepsilon_t = W_{\\varepsilon}[h_t^l;...;h_t^l]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Controller(object):\n",
    "    \n",
    "    def __init__(self, hyperparameter):\n",
    "        \n",
    "        # 初始化 可训练权重矩阵\n",
    "        weights_L1 = self._get_weights('layer_first', hyperparameter)\n",
    "        weights_L2 = self._get_weights('layer_second', hyperparameter)\n",
    "        weights_L3 = self._get_weights('layer_third', hyperparameter)\n",
    "        weights_L4 = self._get_weights('layer_fourth', hyperparameter)\n",
    "        \n",
    "        hidden_num = hyperparameter['hidden_num']\n",
    "        read_head_num = R = hyperparameter['read_head_num']\n",
    "        out_width = hyperparameter['out_width']\n",
    "        W = hyperparameter['memory_W']\n",
    "        interface_width = R*W + 5*R + 3*W + 3\n",
    "        weight_output = tf.get_variable('weight_output', shape=[hidden_num*4, out_width], dtype=tf.float32, initializer=tf.truncated_normal_initializer(0.01))\n",
    "        weight_interface = tf.get_variable('weight_interface', shape=[hidden_num*4, interface_width], dtype=tf.float32, initializer=tf.truncated_normal_initializer(0.01))\n",
    "        \n",
    "        self.weights_trainable = (weights_L1, weights_L2, weights_L3, weights_L4, weight_output, weight_interface)\n",
    "        \n",
    "        \n",
    "    def _get_weights(self, flag, hyperparameter):\n",
    "        \n",
    "        \"\"\"\n",
    "        weights_input: [in_width, hidden_num]\n",
    "        weights_read_vectors_prev: [memory_W * read_head_num, hidden_num]\n",
    "        weights_hidden_prev: [hidden_num, hidden_num]\n",
    "        weights_hidden_lower: [hidden_num, hidden_num]\n",
    "        biaes: [hidden_num]    \n",
    "        \"\"\"\n",
    "        read_head_num = hyperparameter['read_head_num']\n",
    "        in_width = hyperparameter['in_width']\n",
    "        memory_W = hyperparameter['memory_W']\n",
    "        hidden_num = hyperparameter['hidden_num']\n",
    "        \n",
    "        init = tf.truncated_normal_initializer(stddev=0.1)\n",
    "        \n",
    "        weights = {}\n",
    "\n",
    "        # input_gate\n",
    "        weights['input_gate_inputs'] = tf.get_variable(str(flag)+'input_gate_inputs', \n",
    "                                                       shape=[in_width, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['input_gate_read_vectors_prev'] = tf.get_variable(str(flag)+'input_gate_read_vectors_prev', \n",
    "                                                                  shape=[memory_W*read_head_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['input_gate_hidden_prev'] = tf.get_variable(str(flag)+'input_gate_hidden_prev', \n",
    "                                                            shape=[hidden_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['input_gate_hidden_lower'] = tf.get_variable(str(flag)+'input_gate_hidden_lower', \n",
    "                                                             shape=[hidden_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['input_gate_bias'] = tf.get_variable(str(flag)+'input_gate_bias', \n",
    "                                                     shape=[hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        \n",
    "        # forget_gate\n",
    "        weights['forget_gate_inputs'] = tf.get_variable(str(flag)+'forget_gate_inputs', \n",
    "                                                        shape=[in_width, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['forget_gate_read_vectors_prev'] = tf.get_variable(str(flag)+'forget_gate_read_vectors_prev', \n",
    "                                                                   shape=[memory_W*read_head_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['forget_gate_hidden_prev'] = tf.get_variable(str(flag)+'forget_gate_hidden_prev', \n",
    "                                                             shape=[hidden_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['forget_gate_hidden_lower'] = tf.get_variable(str(flag)+'forget_gate_hidden_lower', \n",
    "                                                              shape=[hidden_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['forget_gate_bias'] = tf.get_variable(str(flag)+'forget_gate_bias', \n",
    "                                                      shape=[hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        # state\n",
    "        weights['state_inputs'] = tf.get_variable(str(flag)+'state_inputs', \n",
    "                                                  shape=[in_width, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['state_read_vectors_prev'] = tf.get_variable(str(flag)+'state_read_vectors_prev', \n",
    "                                                             shape=[memory_W*read_head_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['state_hidden_prev'] = tf.get_variable(str(flag)+'state_hidden_prev', \n",
    "                                                       shape=[hidden_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['state_hidden_lower'] = tf.get_variable(str(flag)+'state_hidden_lower', \n",
    "                                                        shape=[hidden_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['state_bias'] = tf.get_variable(str(flag)+'state_bias', \n",
    "                                                shape=[hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        # output_gate\n",
    "        weights['output_gate_inputs'] = tf.get_variable(str(flag)+'output_gate_inputs', \n",
    "                                                        shape=[in_width, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['output_gate_read_vectors_prev'] = tf.get_variable(str(flag)+'output_gate_read_vectors_prev', \n",
    "                                                                   shape=[memory_W*read_head_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['output_gate_hidden_prev'] = tf.get_variable(str(flag)+'output_gate_hidden_prev', \n",
    "                                                             shape=[hidden_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['output_gate_hidden_lower'] = tf.get_variable(str(flag)+'output_gate_hidden_lower', \n",
    "                                                              shape=[hidden_num, hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        weights['output_gate_bias'] = tf.get_variable(str(flag)+'output_gate_bias', \n",
    "                                                      shape=[hidden_num], dtype=tf.float32, initializer=init)\n",
    "        \n",
    "        return weights    \n",
    "    \n",
    "    \n",
    "    def _element(self, inputs, read_vectors_prev, hidden_prev, hidden_lower, state_prev, weights):\n",
    "        \n",
    "        \"\"\"\n",
    "        inputs: [batch_size, in_width]\n",
    "        * read_vectors_prev: [batch_size, memory_W * read_head_num]\n",
    "        hidden_prev: [batch_size, hidden_num]\n",
    "        hidden_lower: [batch_size, hidden_num]\n",
    "        state_prev: [batch_size, hidden_num]\n",
    "         \n",
    "        weights_input: [in_width, hidden_num]\n",
    "        weights_read_vectors_prev: [memory_W * read_head_num, hidden_num]\n",
    "        weights_hidden_prev: [hidden_num, hidden_num]\n",
    "        weights_hidden_lower: [hidden_num, hidden_num]\n",
    "        biaes: [hidden_num]    \n",
    "        \n",
    "        input_gate: [batch_size, hidden_num]\n",
    "        forget_gate: [batch_size, hidden_num]\n",
    "        state: [batch_size. hidden_num]\n",
    "        output_gate: [batch_size, hidden_num]\n",
    "        hidden: [batch_size, hidden_num]\n",
    "        \"\"\"               \n",
    "        \n",
    "        input_gate = tf.nn.sigmoid(tf.matmul(inputs, weights['input_gate_inputs']) + \n",
    "                                   tf.matmul(read_vectors_prev, weights['input_gate_read_vectors_prev']) + \n",
    "                                   tf.matmul(hidden_prev, weights['input_gate_hidden_prev']) + \n",
    "                                   tf.matmul(hidden_lower, weights['input_gate_hidden_lower']) + \n",
    "                                   weights['input_gate_bias'])        \n",
    "\n",
    "        forget_gate = tf.nn.sigmoid(tf.matmul(inputs, weights['forget_gate_inputs']) + \n",
    "                                    tf.matmul(read_vectors_prev, weights['forget_gate_read_vectors_prev']) + \n",
    "                                    tf.matmul(hidden_prev, weights['forget_gate_hidden_prev']) + \n",
    "                                    tf.matmul(hidden_lower, weights['forget_gate_hidden_lower']) + \n",
    "                                    weights['forget_gate_bias'])        \n",
    "        \n",
    "        state = tf.multiply(forget_gate, state_prev) + \\\n",
    "        tf.multiply(input_gate, tf.tanh(tf.matmul(inputs, weights['state_inputs']) + \n",
    "                                        tf.matmul(read_vectors_prev, weights['state_read_vectors_prev']) + \n",
    "                                        tf.matmul(hidden_prev, weights['state_hidden_prev']) + \n",
    "                                        tf.matmul(hidden_lower, weights['state_hidden_lower']) + \n",
    "                                        weights['state_bias']))\n",
    "        \n",
    "        output_gate = tf.nn.sigmoid(tf.matmul(inputs, weights['output_gate_inputs']) + \n",
    "                                    tf.matmul(read_vectors_prev, weights['output_gate_read_vectors_prev']) + \n",
    "                                    tf.matmul(hidden_prev, weights['output_gate_hidden_prev']) + \n",
    "                                    tf.matmul(hidden_lower, weights['output_gate_hidden_lower']) + \n",
    "                                    weights['output_gate_bias'])  \n",
    "        \n",
    "        hidden = tf.multiply(output_gate, state)\n",
    "        \n",
    "        return hidden, state\n",
    "    \n",
    "\n",
    "    def _unit(self, inputs, read_vectors_prev, tape):    \n",
    "        \n",
    "        # Trainable weight parameter\n",
    "        weights_L1, weights_L2, weights_L3, weights_L4, weight_output, weight_interface = self.weights_trainable\n",
    "        \n",
    "        # Variables looping\n",
    "        hidden_L1_prev, hidden_L1_lower, state_L1_prev,\\\n",
    "        hidden_L2_prev, state_L2_prev,\\\n",
    "        hidden_L3_prev, state_L3_prev,\\\n",
    "        hidden_L4_prev, state_L4_prev = tape\n",
    "        \n",
    "        # input layer\n",
    "        hidden_L1, state_L1 = self._element(inputs, read_vectors_prev, hidden_L1_prev, hidden_L1_lower, state_L1_prev, weights_L1)\n",
    "        \n",
    "        # primary thinking layer\n",
    "        hidden_L2_lower = hidden_L1\n",
    "        hidden_L2, state_L2 = self._element(inputs, read_vectors_prev, hidden_L2_prev, hidden_L2_lower, state_L2_prev, weights_L2)\n",
    "        \n",
    "        # advanced thinking layer\n",
    "        hidden_L3_lower = hidden_L2\n",
    "        hidden_L3, state_L3 = self._element(inputs, read_vectors_prev, hidden_L3_prev, hidden_L3_lower, state_L3_prev, weights_L3)\n",
    "        \n",
    "        # output layer\n",
    "        hidden_L4_lower = hidden_L3\n",
    "        hidden_L4, state_L4 = self._element(inputs, read_vectors_prev, hidden_L4_prev, hidden_L4_lower, state_L4_prev, weights_L4)\n",
    "        \n",
    "        \"\"\"\n",
    "        hidden: [batch_size, hidden_num]\n",
    "        hiddens: [batch_size, hidden_num * layers=4]\n",
    "        \n",
    "        weight_output: [4 * hidden_num, out_width]\n",
    "        weight_interface: [4 * hidden_num, W*R+5R+3W+3]\n",
    "        \n",
    "        output_vector: [batch_size, out_width]\n",
    "        interface_vector: [batch_size, W*R+5R+3W+3]\n",
    "        \"\"\"\n",
    "        hiddens = tf.concat([hidden_L1, hidden_L2, hidden_L3, hidden_L4], axis=1)       \n",
    "        output_vector = tf.matmul(hiddens, weight_output)\n",
    "        interface_vector = tf.matmul(hiddens, weight_interface)   \n",
    "        \n",
    "        # Variables looping\n",
    "        tape = (hidden_L1, hidden_L1_lower, state_L1,\\\n",
    "        hidden_L2, state_L2,\\\n",
    "        hidden_L3, state_L3,\\\n",
    "        hidden_L4, state_L4)        \n",
    "        \n",
    "        return tape, interface_vector, output_vector\n",
    "    \n",
    "    \n",
    "    def step(self, inputs, read_vectors_prev, tape):\n",
    "        tape, interface_vector, output_vector = self._unit(inputs, read_vectors_prev, tape)\n",
    "        return tape, interface_vector, output_vector   \n",
    "\n",
    "\n",
    "    def zero_state(self, hyperparameter):\n",
    "        \n",
    "        batch_size = hyperparameter['batch_size']\n",
    "        hidden_num = hyperparameter['hidden_num']\n",
    "        \n",
    "        hidden_L1_prev = tf.zeros([batch_size, hidden_num], dtype=tf.float32)\n",
    "        hidden_L0 = tf.zeros([batch_size, hidden_num], dtype=tf.float32)\n",
    "        state_L1_prev = tf.zeros([batch_size, hidden_num], dtype=tf.float32)\n",
    "        \n",
    "        hidden_L2_prev = tf.zeros([batch_size, hidden_num], dtype=tf.float32)\n",
    "        state_L2_prev = tf.zeros([batch_size, hidden_num], dtype=tf.float32)\n",
    "\n",
    "        hidden_L3_prev = tf.zeros([batch_size, hidden_num], dtype=tf.float32)\n",
    "        state_L3_prev = tf.zeros([batch_size, hidden_num], dtype=tf.float32)\n",
    "\n",
    "        hidden_L4_prev = tf.zeros([batch_size, hidden_num], dtype=tf.float32)\n",
    "        state_L4_prev = tf.zeros([batch_size, hidden_num], dtype=tf.float32)                \n",
    "\n",
    "        tape = (hidden_L1_prev, hidden_L0, state_L1_prev,\\\n",
    "                hidden_L2_prev, state_L2_prev,\\\n",
    "                hidden_L3_prev, state_L3_prev,\\\n",
    "                hidden_L4_prev, state_L4_prev)\n",
    "        \n",
    "        return tape    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Addressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Memory_Addressing(object):\n",
    "    \n",
    "    def __init__(self, batch_size, memory_N):\n",
    "        self.batch_size = batch_size\n",
    "        self.memory_N = memory_N\n",
    "        self.mask_eye = 1 - tf.eye(memory_N) \n",
    "        self.flat_shift = tf.constant(value= np.arange(self.batch_size)*self.memory_N, dtype=tf.int32, shape=[self.batch_size,1])\n",
    "        self.eps = 1e-6\n",
    "\n",
    "    # 余弦相似性的内容寻址\n",
    "    def _Content_based_addressing(self, memory_matrix, lookup_key, key_strength):\n",
    "        \"\"\"\n",
    "        memory_matrix: [batch_size, memory_N, memory_W]\n",
    "        lookup_key: [batch_size, memory_W, read_head_num or write_head_num]\n",
    "        key_strength: [batch_size, read_head_num or write_head_num] -> [batch_size, 1, read_head_num or write_head_num] \n",
    "        cosine_similarity: [batch_size, memory_N, read_head_num or write_head_num]\n",
    "        content_weighting: [batch_size, memory_N, read_head_num or write_head_num]\n",
    "        \"\"\"\n",
    "        # 计算余弦相似性 点乘数量积\n",
    "        cosine_similarity = tf.matmul(tf.nn.l2_normalize(memory_matrix, dim=2), tf.nn.l2_normalize(lookup_key, dim=1))\n",
    "        content_weighting = tf.nn.softmax(tf.multiply(cosine_similarity, tf.expand_dims(key_strength, axis=1)), dim=1)\n",
    "        return content_weighting\n",
    "    \n",
    "    # 动态内存分配，retention_vector 根据所有读头反馈决定memory_matrix 矩阵索引memory_N的不被释放的程度    \n",
    "    def _Dynamic_memory_allocation(self, free_gates, read_weightings_prev, write_weighting_prev, usage_vector_prev):\n",
    "        \"\"\"\n",
    "        * free_gates: [batch_size, read_head_num] -> [batch_size, 1, read_head_num]       \n",
    "        read_weightings_prev: [batch_size, memory_N, read_head_num]\n",
    "        retention_vector: [batch_size, memory_N]\n",
    "        \n",
    "        write_weighting_prev: [batch_size, memory_N]\n",
    "        usage_vector_prev: [batch_size, memory_N]\n",
    "        usage_vector: [batch_size, memory_N]\n",
    "\n",
    "        allocation_weighting: [batch_size, memory_N]\n",
    "        \n",
    "        Note: * read_weightings_prev: [batch_size, memory_N, read_head_num]\n",
    "              * write_weighting_prev: [batch_size, memory_N]\n",
    "        \"\"\"\n",
    "        free_gates = tf.expand_dims(free_gates, axis=1)\n",
    "        retention_vector = tf.reduce_prod(1 - tf.multiply(read_weightings_prev, free_gates), axis=2)       \n",
    "        \n",
    "        usage_vector = tf.multiply((usage_vector_prev + write_weighting_prev - tf.multiply(usage_vector_prev, write_weighting_prev)), retention_vector)\n",
    "        \n",
    "        values, indices = tf.nn.top_k(usage_vector, k=self.memory_N)  # 降序排列    \n",
    "        values_sorted = tf.reverse(values, axis=[1]) # 值 升序\n",
    "        indices_sorted = tf.reverse(indices, axis=[1]) # 索引 升序\n",
    "        allocation_weighting = tf.multiply((1-values_sorted), tf.cumprod(values_sorted, axis=1, exclusive=True))\n",
    "        \"\"\"\n",
    "        allocation_weighting 值返回原始位置\n",
    "        这里根据论文计算的公式论文里面使用的索引计算方式，也就是按索引顺序的计算得出上面的矩阵，还需要返回正常的顺序。\n",
    "        通过TensorArray操作将allocation_weighting 返回原来的序列，也就是usage_vector 最初对应的序列，也就是memory 矩阵的正常序列，\n",
    "        返回的数值为根据 allocation_weighting 计算的释放程度的值\n",
    "        \"\"\"\n",
    "        indices_flat = tf.reshape(tensor= indices_sorted + self.flat_shift, shape=[-1])\n",
    "        flat_array = tf.TensorArray(dtype=tf.float32, size=self.batch_size*self.memory_N)\n",
    "        scatter= flat_array.scatter(indices= indices_flat, value= tf.reshape(allocation_weighting, shape=[-1]))\n",
    "        allocation_sort_undo = scatter.stack()\n",
    "        allocation_weighting = tf.reshape(allocation_sort_undo, shape=[self.batch_size, self.memory_N])     \n",
    "        allocation_weighting = tf.stop_gradient(allocation_weighting)\n",
    "        #usage_vector = tf.stop_gradient(usage_vector)\n",
    "        return allocation_weighting, usage_vector\n",
    "    \n",
    "    # 更新写头分布权重\n",
    "    def _Write_weighting(self, memory_matrix_prev, write_key, write_strength, \n",
    "                         free_gates, read_weightings_prev, write_weighting_prev, usage_vector_prev, \n",
    "                         allocation_gate, write_gate):\n",
    "        \"\"\"\n",
    "        memory_matrix_prev: [batch_size, memory_N, memory_W]\n",
    "        write_key: [batch_size, memory_W, write_head_num= 1]\n",
    "        write_strength: [batch_size, 1]\n",
    "        * write_content_weighting: [batch_size, memory_N, 1] -> write_content_weighting: [batch_size, memory_N]\n",
    "\n",
    "        free_gates: [batch_size, read_head_num] ->  [batch_size, 1, read_head_num]       \n",
    "        read_weightings_prev: [batch_size, memory_N, read_head_num]\n",
    "        write_weighting_prev: [batch_size, memory_N]\n",
    "        usage_vector_prev: [batch_size, memory_N]\n",
    "        allocation_weighting: [batch_size, memory_N]\n",
    "        usage_vector: [batch_size, memory_N]\n",
    "\n",
    "        allocation_gate: [batch_size, 1]\n",
    "        write_gate: [batch_size, 1]        \n",
    "        write_weighting: [batch_size, memory_N]\n",
    "        \"\"\"\n",
    "        write_content_weighting = tf.squeeze(self._Content_based_addressing(memory_matrix_prev, write_key, write_strength), axis=[2])\n",
    "        allocation_weighting, usage_vector = self._Dynamic_memory_allocation(free_gates, read_weightings_prev, write_weighting_prev, usage_vector_prev)\n",
    "        write_weighting = tf.multiply((tf.multiply(allocation_weighting, allocation_gate) + tf.multiply(write_content_weighting, (1-allocation_gate))), write_gate)\n",
    "        return write_weighting, usage_vector \n",
    "    \n",
    "    \n",
    "    # 时间记忆链\n",
    "    def _Temporal_memory_linkage(self, write_weighting, precedence_weighting_prev, \n",
    "                                link_matrix_prev, \n",
    "                                read_weightings_prev):        \n",
    "        \"\"\"\n",
    "        write_weighting: [batch_size, memory_N]\n",
    "        precedence_weighting_prev: [batch_size, memory_N]\n",
    "        precedence_weighting: [batch_size, memory_N]\n",
    "        \n",
    "        * write_weighting: [batch_size, memory_N] -> write_weighting: [batch_size, memory_N, 1]\n",
    "        tmp: [batch_size, memory_N, memory_N]\n",
    "        link_marix_prev: [batch_size, memory_N, memory_N]\n",
    "        left: [batch_size, memory_N, memory_N]\n",
    "        * precedence_weighting_fit: [batch_size, memory_N] -> precedence_weighting: [batch_size, 1, memory_N] 维度匹配\n",
    "        right: [batch_size, memory_N, memory_N]\n",
    "        link_marix: [batch_size, memory_N, memory_N]\n",
    "        \n",
    "        read_weightings_prev: [batch_size, memory_N, read_head_num]\n",
    "        forward_weighting: [batch_size, memory_N, read_head_num]\n",
    "        backward_weighting: [batch_size, memory_N, read_head_num]\n",
    "        \"\"\"\n",
    "        \n",
    "        precedence_weighting = tf.multiply(precedence_weighting_prev, (1 - tf.reduce_sum(write_weighting, axis=1, keep_dims=True))) + write_weighting\n",
    "        \n",
    "        write_weighting = tf.expand_dims(write_weighting, axis=2)\n",
    "        tmp = tf.tile(write_weighting, multiples=[1,1,self.memory_N])\n",
    "        left = tf.multiply(link_matrix_prev, (1 - tmp - tf.transpose(tmp,perm=[0,2,1])))\n",
    "        precedence_weighting_fit = tf.expand_dims(precedence_weighting_prev, axis=1) # 维度匹配\n",
    "        right = tf.matmul(write_weighting, precedence_weighting_fit)        \n",
    "        link_matrix = tf.multiply((left+right), self.mask_eye) # 掩码处理对角线消除\n",
    "\n",
    "        forward_weighting = tf.matmul(link_matrix, read_weightings_prev)\n",
    "        backward_weighting = tf.matmul(link_matrix, read_weightings_prev, transpose_a=True)\n",
    "\n",
    "        return forward_weighting, backward_weighting, link_matrix, precedence_weighting\n",
    "    \n",
    "    \n",
    "    # 更新读头权重参数\n",
    "    def _Read_weighting(self, memory_matrix, read_keys, read_strengths, \n",
    "                        write_weighting, precedence_weighting_prev, \n",
    "                        link_matrix_prev, \n",
    "                        read_weightings_prev, \n",
    "                        read_modes):\n",
    "        \n",
    "        \"\"\"\n",
    "        memory_matrix: [batch_size, memory_N, memory_W]\n",
    "        read_keys: [batch_size, memory_N, read_head_num]\n",
    "        read_strengths: [batch_size, read_head_num]\n",
    "        read_content_weighting: [batch_size, memory_N, read_head_num]\n",
    "        \n",
    "        write_weighting: [batch_size, memory_N] \n",
    "        precedence_weighting_prev: [batch_size, memory_N]\n",
    "        link_marix_prev: [batch_size, memory_N, memory_N]\n",
    "        read_weightings_prev: [batch_size, memory_N, read_head_num]\n",
    "        forward_weighting: [batch_size, memory_N, read_head_num]\n",
    "        backward_weighting: [batch_size, memory_N, read_head_num]\n",
    "        link_marix: [batch_size, memory_N, memory_N]\n",
    "        precedence_weighting: [batch_size, memory_N] \n",
    "        \n",
    "        read_modes: [batch_size, 3, read_head_num]\n",
    "        forward: [batch_size, memory_N, read_head_num]\n",
    "        backward: [batch_size, memory_N, read_head_num]\n",
    "        content: [batch_size, memory_N, read_head_num]\n",
    "        \n",
    "        read_weightings: [batch_size, memory_N, read_head_num]\n",
    "        \"\"\"\n",
    "        read_content_weightings = self._Content_based_addressing(memory_matrix, read_keys, read_strengths)\n",
    "        \n",
    "        forward_weighting, backward_weighting, link_matrix, precedence_weighting = \\\n",
    "        self._Temporal_memory_linkage(write_weighting, precedence_weighting_prev, link_matrix_prev, read_weightings_prev)\n",
    "\n",
    "        backward = tf.multiply(backward_weighting, tf.expand_dims(read_modes[:,0,:], axis=1))\n",
    "        content = tf.multiply(read_content_weightings, tf.expand_dims(read_modes[:,1,:], axis=1))\n",
    "        forward = tf.multiply(forward_weighting, tf.expand_dims(read_modes[:,2,:], axis=1))\n",
    "        read_weightings = backward + content + forward\n",
    "        return read_weightings, precedence_weighting, link_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 外部缓存交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class External_Cache(Memory_Addressing):\n",
    "    \n",
    "    def __init__(self, hyperparameter):\n",
    "        Memory_Addressing.__init__(self, hyperparameter['batch_size'], hyperparameter['memory_N'])\n",
    "        self.memory_W = hyperparameter['memory_W']\n",
    "        self.read_head_num = hyperparameter['read_head_num']\n",
    "        \n",
    "        \n",
    "    def _Interface_parameters(self, interface_vector):\n",
    "        # 处理控制器发出接口向量\n",
    "        \"\"\"\n",
    "        interface_vector: [batch_size, W*R+5R+3W+3]\n",
    "        \n",
    "        * read_keys: [batch_size, memory_W * read_head_num] -> [batch_size, memory_W, read_head_num]\n",
    "        read_strengths: [batch_size, read_head_num]\n",
    "        * write_key: [batch_size, memory_W] -> [batch_size, memory_W, write_head_num=1]\n",
    "        write_strengths: [batch_size, write_head_num=1]\n",
    "        erase_vector: [batch_size, memory_W]\n",
    "        write_vector: [batch_size, memory_W]\n",
    "        free_gates: [batch_size, read_head_num]\n",
    "        allocation_gate: [batch_size, 1]\n",
    "        write_gate: [batch_size, 1]\n",
    "        * read_modes: [batch_size, 3 * read_head_num] -> [batch_size, 3, read_head_num]\n",
    "        \"\"\"\n",
    "        R,W = self.read_head_num, self.memory_W        \n",
    "        splits = np.cumsum([0,W*R,R,W,1,W,W,R,1,1,3*R])        \n",
    "        tmp_list = [interface_vector[:, splits[i]:splits[i+1]] for i in range(len(splits)-1)]\n",
    "        \n",
    "        read_keys = tf.reshape(tmp_list[0], shape=[-1, self.memory_W, self.read_head_num])\n",
    "        read_strengths = 1 + tf.nn.softplus(tf.reshape(tmp_list[1], shape=[-1, self.read_head_num]))\n",
    "        write_key = tf.reshape(tmp_list[2], shape=[-1, self.memory_W, 1])\n",
    "        write_strength = 1 + tf.nn.softplus(tf.reshape(tmp_list[3], shape=[-1,1]))\n",
    "        erase_vector = tf.nn.sigmoid(tf.reshape(tmp_list[4], shape=[-1, self.memory_W]))\n",
    "        write_vector = tf.reshape(tmp_list[5], shape=[-1, self.memory_W])\n",
    "        free_gates = tf.nn.sigmoid(tf.reshape(tmp_list[6], shape=[-1, self.read_head_num]))\n",
    "        allocation_gate = tf.nn.sigmoid(tmp_list[7])        \n",
    "        write_gate = tf.nn.sigmoid(tmp_list[8])\n",
    "        read_modes = tf.nn.softmax(tf.reshape(tmp_list[9], shape=[-1, 3, self.read_head_num]))        \n",
    "        \n",
    "\n",
    "    def _reading_and_writing_to_memory(self, tape, interface_vector):\n",
    "\n",
    "        # 处理控制器发出接口向量\n",
    "        \"\"\"\n",
    "        interface_vector: [batch_size, W*R+5R+3W+3]\n",
    "        \n",
    "        * read_keys: [batch_size, memory_W * read_head_num] -> [batch_size, memory_W, read_head_num]\n",
    "        read_strengths: [batch_size, read_head_num]\n",
    "        * write_key: [batch_size, memory_W] -> [batch_size, memory_W, write_head_num=1]\n",
    "        write_strengths: [batch_size, write_head_num=1]\n",
    "        erase_vector: [batch_size, memory_W]\n",
    "        write_vector: [batch_size, memory_W]\n",
    "        free_gates: [batch_size, read_head_num]\n",
    "        allocation_gate: [batch_size, 1]\n",
    "        write_gate: [batch_size, 1]\n",
    "        * read_modes: [batch_size, 3 * read_head_num] -> [batch_size, 3, read_head_num]\n",
    "        \"\"\"\n",
    "        R,W = self.read_head_num, self.memory_W        \n",
    "        splits = np.cumsum([0,W*R,R,W,1,W,W,R,1,1,3*R])        \n",
    "        tmp_list = [interface_vector[:, splits[i]:splits[i+1]] for i in range(len(splits)-1)]\n",
    "        \n",
    "        read_keys = tf.reshape(tmp_list[0], shape=[-1, self.memory_W, self.read_head_num])\n",
    "        read_strengths = 1 + tf.nn.softplus(tf.reshape(tmp_list[1], shape=[-1, self.read_head_num]))\n",
    "        write_key = tf.reshape(tmp_list[2], shape=[-1, self.memory_W, 1])\n",
    "        write_strength = 1 + tf.nn.softplus(tf.reshape(tmp_list[3], shape=[-1,1]))\n",
    "        erase_vector = tf.nn.sigmoid(tf.reshape(tmp_list[4], shape=[-1, self.memory_W]))\n",
    "        write_vector = tf.reshape(tmp_list[5], shape=[-1, self.memory_W])\n",
    "        free_gates = tf.nn.sigmoid(tf.reshape(tmp_list[6], shape=[-1, self.read_head_num]))\n",
    "        allocation_gate = tf.nn.sigmoid(tmp_list[7])        \n",
    "        write_gate = tf.nn.sigmoid(tmp_list[8])\n",
    "        read_modes = tf.nn.softmax(tf.reshape(tmp_list[9], shape=[-1, 3, self.read_head_num]))        \n",
    "        \n",
    "        # 处理循环数据\n",
    "        \"\"\"\n",
    "        memory_matrix_prev: [batch_size, memory_N, memory_W]\n",
    "        read_weightings_prev: [batch_size, memory_N, read_head_num]\n",
    "        write_weighting_prev: [batch_size, memory_N]\n",
    "        usage_vector_prev: [batch_size, memory_N]\n",
    "        link_marix_prev: [batch_size, memory_N, memory_N]\n",
    "        precedence_weighting_prev: [batch_size, memory_N]\n",
    "        \"\"\"  \n",
    "        memory_matrix_prev = tape[0]\n",
    "        read_weightings_prev = tape[1]\n",
    "        write_weighting_prev = tape[2]\n",
    "        usage_vector_prev = tape[3]\n",
    "        link_matrix_prev = tape[4]\n",
    "        precedence_weighting_prev = tape[5]\n",
    "        \n",
    "        # Memory addressing -> write weighting       \n",
    "        \"\"\"\n",
    "        memory_matrix_prev: [batch_size, memory_N, memory_W]\n",
    "        write_key: [batch_size, memory_W, write_head_num=1]\n",
    "        write_strengths: [batch_size, write_head_num=1]\n",
    "        \n",
    "        free_gates: [batch_size, read_head_num]\n",
    "        read_weightings_prev: [batch_size, memory_N, read_head_num]\n",
    "        write_weighting_prev: [batch_size, memory_N]\n",
    "        usage_vector_prev: [batch_size, memory_N]\n",
    "        \n",
    "        allocation_gate: [batch_size, 1]\n",
    "        write_gate = tf.nn.sigmoid(tmp_list[8])\n",
    "        \n",
    "        write_weighting: [batch_size, memory_N]\n",
    "        usage_vector: [batch_size, memory_N]\n",
    "        \"\"\"\n",
    "        write_weighting, usage_vector = self._Write_weighting(memory_matrix_prev, write_key, write_strength, \n",
    "                                                              free_gates, read_weightings_prev, write_weighting_prev, usage_vector_prev,\n",
    "                                                              allocation_gate, write_gate)\n",
    "        \n",
    "        \n",
    "        # reading and writing to memory -> update memory\n",
    "        \"\"\"\n",
    "        write_weighting: [batch_size, memory_N]\n",
    "        * write_weighting_fit: [batch_size, memory_N] -> write_weighting: [batch_size, memory_N, 1]\n",
    "        erase_vector: [batch_size, memory_W] -> erase_vector: [batch_size, 1, memory_W]\n",
    "        write_vector: [batch_size, memory_W] -> write_vector: [batch_size, 1, memory_W]\n",
    "        \n",
    "        memory_matrix_prev: [batch_size, memory_N, memory_W]\n",
    "        \"\"\"\n",
    "        write_weighting_fit = tf.expand_dims(write_weighting, axis=2)\n",
    "        erase_vector = tf.expand_dims(erase_vector, axis=1)\n",
    "        write_vector = tf.expand_dims(write_vector, axis=1)\n",
    "        \n",
    "        erase_operation = tf.multiply(memory_matrix_prev, (1-tf.matmul(write_weighting_fit, erase_vector)))\n",
    "        write_operation = tf.matmul(write_weighting_fit, write_vector)\n",
    "        memory_matrix = erase_operation + write_operation        \n",
    "        \n",
    "        # memory addressing -> read weightings\n",
    "        \"\"\"\n",
    "        memory_matrix: [batch_size, memory_N, memory_W]\n",
    "        read_keys: [batch_size, memory_W , read_head_num]\n",
    "        read_strengths: [batch_size, read_head_num]\n",
    "        precedence_weighting_prev: [batch_size, memory_N]\n",
    "        link_marix_prev: [batch_size, memory_N, memory_N]\n",
    "        read_modes: [batch_size, 3 * read_head_num]\n",
    "        read_weightings: [batch_size, memory_N, read_head_num]\n",
    "        precedence_weighting: [batch_size, memory_N]\n",
    "        link_marix: [batch_size, memory_N, memory_N]\n",
    "        \n",
    "        read_vectors: [batch_size, memory_W, read_head_num] \n",
    "        \"\"\"\n",
    "\n",
    "        read_weighting, precedence_weighting, link_matrix = \\\n",
    "        self._Read_weighting(memory_matrix, \n",
    "                             read_keys, read_strengths, \n",
    "                             write_weighting, precedence_weighting_prev, \n",
    "                             link_matrix_prev,\n",
    "                             read_weightings_prev,\n",
    "                             read_modes)      \n",
    "        \n",
    "        read_vectors = tf.matmul(memory_matrix, read_weighting, adjoint_a=True)\n",
    "\n",
    "        # 处理循环数据        \n",
    "        tape = (memory_matrix, read_weighting, write_weighting, usage_vector, link_matrix, precedence_weighting)\n",
    "        # 处理输出数据 read_vectors: [batch_size, memory_W, read_head_num] -> [batch_size, memory_W * read_head_num]\n",
    "        read_vectors = tf.reshape(read_vectors, shape=[-1, R*W])\n",
    "        return tape, read_vectors\n",
    "    \n",
    "    \n",
    "    def step(self, tape, interface_vector):\n",
    "        tape, read_vectors = self._reading_and_writing_to_memory(interface_vector=interface_vector, tape=tape)\n",
    "        return tape, read_vectors       \n",
    "    \n",
    "        \n",
    "    def zero_state(self):        \n",
    "        \"\"\"\n",
    "        memory_matrix_prev: [batch_size, memory_N, memory_W]\n",
    "        read_weightings_prev: [batch_size, memory_N, read_head_num]\n",
    "        write_weighting_prev: [batch_size, memory_N]\n",
    "        usage_vector_prev: [batch_size, memory_N]\n",
    "        link_marix_prev: [batch_size, memory_N, memory_N]\n",
    "        precedence_weighting_prev: [batch_size, memory_N]\n",
    "        \"\"\"\n",
    "        return (tf.fill(dims=[self.batch_size, self.memory_N, self.memory_W], value=self.eps), \n",
    "                tf.fill(dims=[self.batch_size, self.memory_N, self.read_head_num], value=self.eps),\n",
    "                tf.fill(dims=[self.batch_size, self.memory_N], value=self.eps),\n",
    "                tf.zeros([self.batch_size, self.memory_N]),\n",
    "                tf.zeros([self.batch_size, self.memory_N, self.memory_N]),\n",
    "                tf.zeros([self.batch_size, self.memory_N]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNC封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DNC_Seq2Seq(object):\n",
    "    \n",
    "    def __init__(self, inputs, targets, hyperparameter):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.hyperparameter = hyperparameter\n",
    "        \n",
    "        self.Controller = Controller(hyperparameter)\n",
    "        self.Cache = External_Cache(hyperparameter)\n",
    "        self.inputs_placeholder = tf.placeholder(dtype=tf.float32, shape=[hyperparameter['batch_size'], hyperparameter['in_length'], hyperparameter['in_width']])\n",
    "        self.targets_placeholder = tf.placeholder(dtype=tf.float32, shape=[hyperparameter['batch_size'], hyperparameter['out_length'], hyperparameter['out_width']])\n",
    "        self.weight_read_vectors = tf.get_variable('weight_read_vector',\\\n",
    "                                                   shape=[hyperparameter['memory_W'] * hyperparameter['read_head_num'], hyperparameter['out_width']],\\\n",
    "                                                   dtype = tf.float32, initializer = tf.truncated_normal_initializer(0.01))\n",
    "\n",
    "    def _step(self, tape, inputs):\n",
    "        \n",
    "        tape_controller, tape_cache, read_vectors_prev, linear_prev = tape\n",
    "        \n",
    "        tape_controller, interface_vector, output_vector = self.Controller.step(inputs, read_vectors_prev, tape_controller)\n",
    "        tape_cache, read_vectors = self.Cache.step(tape_cache, interface_vector)\n",
    "        linear = output_vector + tf.matmul(read_vectors, self.weight_read_vectors)        \n",
    "        \n",
    "        return (tape_controller, tape_cache, read_vectors, linear)    \n",
    "    \n",
    "    \n",
    "    def _zero_state(self, hyperparameter):    \n",
    "        tape_controller = self.Controller.zero_state(hyperparameter)\n",
    "        tape_cache = self.Cache.zero_state()\n",
    "        read_vectors_prev = tf.zeros([hyperparameter['batch_size'], hyperparameter['memory_W'] * hyperparameter['read_head_num']], dtype=tf.float32)\n",
    "        linear_prev = tf.zeros([hyperparameter['batch_size'], hyperparameter['out_width']], dtype=tf.float32)\n",
    "        \n",
    "        return (tape_controller, tape_cache, read_vectors_prev, linear_prev)      \n",
    "    \n",
    "    def fit(self):\n",
    "        raise NotImplementedError(\"fit does not exist\")\n",
    "        \n",
    "    def pred(self):\n",
    "        raise NotImplementedError(\"pred does not exist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQwAAACKCAYAAADvywdgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f229e47fe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step_length = 5\n",
    "in_width = 7\n",
    "repetitions = 7\n",
    "\n",
    "A = [np.concatenate((np.random.randint(low=0, high=2, size=(step_length, in_width)), np.zeros(shape=[step_length+4, in_width])), axis=0) for _ in range(repetitions)]\n",
    "A = np.vstack(A)[:-2,:]\n",
    "B = np.vstack([A[-step_length-2:,:],A[:-step_length-2]])\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(A.T, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQwAAACKCAYAAADvywdgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAHQEhgAAAABAR2AIAAAAAHT+H3NtbLfupGzkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f229e44a470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(B.T, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQwAAACKCAYAAADvywdgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f229e44a240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(A.T- B.T, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批次数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_generation(step_length= 5, in_width= 7, repetitions= 7):\n",
    "    A = [np.concatenate((np.random.randint(low=0, high=2, size=(step_length, in_width)), np.zeros(shape=[step_length+4, in_width])), axis=0) for _ in range(repetitions)]\n",
    "    A = np.vstack(A)[:-2,:]\n",
    "    B = np.vstack([A[-step_length-2:,:],A[:-step_length-2]])\n",
    "    return A, B\n",
    "\n",
    "def batch_generation(batch_size=32, step_length=11, in_width= 13, repetitions= 3):\n",
    "    A_batch = []\n",
    "    B_batch = []\n",
    "    for _ in range(batch_size):\n",
    "        A, B = sequence_generation(step_length, in_width, repetitions)\n",
    "        A_batch.append(A)\n",
    "        B_batch.append(B)\n",
    "    \n",
    "    A_tensor = np.transpose(np.dstack(A_batch), axes=[2,0,1])\n",
    "    B_tensor = np.transpose(np.dstack(B_batch), axes=[2,0,1])\n",
    "    return A_tensor, B_tensor\n",
    "\n",
    "train_inputs, train_targets = batch_generation()\n",
    "test_inputs, test_targets = batch_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACA8AAAGICAYAAAAk11vbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/nGWzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f229e333400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(26,8))\n",
    "plt.imshow(train_inputs[0].T-train_targets[0].T, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACA8AAAGICAYAAAAk11vbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTh4AAAAAAAAAgLkAn10IcbG2zuUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f229e2a34e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(26,8))\n",
    "plt.imshow(test_inputs[0].T-test_targets[0].T, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for repeat&copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class test_repeat_copy(DNC_Seq2Seq):\n",
    "    \n",
    "    def __init__(self, inputs, targets, hyperparameter):\n",
    "        DNC_Seq2Seq.__init__(self, inputs, targets, hyperparameter)\n",
    "        \n",
    "    def loss_fit(self, pred, targets):\n",
    "        #loss_tensor = -targets*tf.log(pred + 1e-31) - (1-targets)*tf.log(1-pred + 1e-31)\n",
    "        loss_tensor = (pred - targets)**2\n",
    "        return tf.reduce_mean(loss_tensor)\n",
    "        \n",
    "    def fit_clip(self, test_inputs, test_targets, learning_rate=1e-4, momentum=0.9, iterations=1e5, max_grad_norm = 50):      \n",
    "        \n",
    "        out_width = self.hyperparameter['out_width']\n",
    "        tape = self._zero_state(self.hyperparameter)\n",
    "        inputs_placeholder = tf.transpose(a=self.inputs_placeholder, perm=[1,0,2])          \n",
    "        outputs_looping = tf.scan(fn=self._step, elems=inputs_placeholder, initializer=tape)[-1]\n",
    "        \n",
    "        output = tf.transpose(outputs_looping, [1,0,2])\n",
    "        #pred = tf.sigmoid(output)\n",
    "        pred = output\n",
    "\n",
    "        cost = self.loss_fit(pred, self.targets_placeholder)   \n",
    "        \n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate, momentum=momentum)\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        for i, (grad, var) in enumerate(gradients):\n",
    "            if grad is not None:\n",
    "                gradients[i] = (tf.clip_by_value(grad, -5, 5), var)\n",
    "        grad_op = optimizer.apply_gradients(gradients)\n",
    "\n",
    "        correct_pred = tf.equal(tf.round(pred), self.targets_placeholder)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        #tf.summary.scalar('generalization error', test)\n",
    "        tf.summary.scalar(\"loss\", cost)\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "        merged_summary_op = tf.summary.merge_all()\n",
    "        # 绝对路径\n",
    "        logs_path = os.path.join(os.getcwd(),\"logdata\")\n",
    "        \n",
    "        tmp = []\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "            for i in range(np.int(iterations)):\n",
    "                _, loss = sess.run([grad_op, cost], feed_dict={self.inputs_placeholder:self.inputs, self.targets_placeholder:self.targets})\n",
    "                tmp.append(loss)\n",
    "                #_, summary = sess.run([grad_op, merged_summary_op], feed_dict={self.inputs_placeholder:self.inputs, self.targets_placeholder:self.targets})\n",
    "                #summary_writer.add_summary(summary, i)\n",
    "            print (\"Optimization Finished!\")\n",
    "            return tmp\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 76, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.ops.variables.Variable at 0x7f229e316ac8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e316e48>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e316b70>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e44a358>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e44a6d8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e44a048>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e2616a0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e337c50>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e27aa58>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e28c1d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dfeec50>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df81cc0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e3335c0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e333160>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e3337b8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e3333c8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e3336d8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e3334e0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229e333b70>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dfa7da0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dfba908>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dfbaf28>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dfdaf28>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dfda550>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dfdaac8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df729b0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df04be0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df94cc0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df94da0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df2ccc0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df3f828>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df3fe48>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df5def0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df5d470>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df5d9e8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de87f60>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229def6fd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df16cc0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229df16be0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229deaebe0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de41748>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de41d68>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dee3908>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dee3390>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dee3f28>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de7aeb8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de0ae80>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de9bb70>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de9bb00>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de1ffd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de1fa20>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de33f60>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de33b00>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229ddc7c88>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229ddffdd8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dd91da0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de66828>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de662b0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229de66e48>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dda4eb8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dda4940>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dd5cf98>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229ddb7f28>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229ddb7a20>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dd4b9e8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dd04cf8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dd16cc0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dde9748>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dde91d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dde9d68>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dd3ef60>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dd3e940>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dce1eb8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dce1fd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dcf69e8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dc87c18>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dc9abe0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dcd0ef0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dd71668>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dd71c88>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dcbee80>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dcbe860>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f229dbd8c18>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter = {}\n",
    "hyperparameter['batch_size'] = 32\n",
    "hyperparameter['in_length'] =76\n",
    "hyperparameter['in_width'] = 13\n",
    "hyperparameter['out_length'] = 76\n",
    "hyperparameter['out_width'] = 13\n",
    "hyperparameter['hidden_num'] = 20\n",
    "hyperparameter['memory_N'] = 20\n",
    "hyperparameter['memory_W'] = 13\n",
    "hyperparameter['read_head_num'] = 3\n",
    "\n",
    "test = test_repeat_copy(train_inputs, train_targets, hyperparameter)\n",
    "\n",
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "test_pred = test.fit_clip(test_inputs, test_targets, iterations=1e3, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2257f2e7b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAFeCAYAAAA7eE02AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7dfxjFo/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2258a76e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = pd.Series(test_pred)\n",
    "p.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.093870\n",
       "1      2.959617\n",
       "2      2.738933\n",
       "3      2.474893\n",
       "4      2.211662\n",
       "5      1.970040\n",
       "6      1.765759\n",
       "7      1.599944\n",
       "8      1.469898\n",
       "9      1.368302\n",
       "10     1.288251\n",
       "11     1.222068\n",
       "12     1.164127\n",
       "13     1.110253\n",
       "14     1.057896\n",
       "15     1.006410\n",
       "16     0.955789\n",
       "17     0.906541\n",
       "18     0.859613\n",
       "19     0.815935\n",
       "20     0.775606\n",
       "21     0.739777\n",
       "22     0.708141\n",
       "23     0.680477\n",
       "24     0.656627\n",
       "25     0.635303\n",
       "26     0.616657\n",
       "27     0.599777\n",
       "28     0.584136\n",
       "29     0.568970\n",
       "         ...   \n",
       "970    0.096087\n",
       "971    0.096159\n",
       "972    0.096065\n",
       "973    0.095920\n",
       "974    0.096079\n",
       "975    0.095961\n",
       "976    0.095913\n",
       "977    0.095998\n",
       "978    0.095767\n",
       "979    0.095845\n",
       "980    0.095932\n",
       "981    0.095816\n",
       "982    0.095876\n",
       "983    0.095781\n",
       "984    0.096068\n",
       "985    0.096089\n",
       "986    0.095928\n",
       "987    0.095899\n",
       "988    0.095794\n",
       "989    0.095790\n",
       "990    0.095926\n",
       "991    0.095752\n",
       "992    0.095691\n",
       "993    0.095662\n",
       "994    0.095728\n",
       "995    0.095792\n",
       "996    0.095683\n",
       "997    0.095791\n",
       "998    0.095689\n",
       "999    0.095550\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
