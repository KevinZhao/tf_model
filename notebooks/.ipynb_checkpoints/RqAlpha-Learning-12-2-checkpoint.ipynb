{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义获取数据函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_data(path):\n",
    "    tmp = pd.read_csv(path, encoding=\"gbk\", engine='python')\n",
    "    tmp.rename(columns={'Unnamed: 0':'trading_time'}, inplace=True)\n",
    "    tmp['trading_point'] = pd.to_datetime(tmp.trading_time)\n",
    "    del tmp['trading_time']\n",
    "    tmp.set_index(tmp.trading_point, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "def High_2_Low(tmp, freq):\n",
    "    \"\"\"处理从RiceQuant下载的分钟线数据，\n",
    "    从分钟线数据合成低频数据\n",
    "    2017-08-11    \n",
    "    \"\"\"\n",
    "    # 分别处理bar数据\n",
    "    tmp_open = tmp['open'].resample(freq).ohlc()\n",
    "    tmp_open = tmp_open['open'].dropna()\n",
    "\n",
    "    tmp_high = tmp['high'].resample(freq).ohlc()\n",
    "    tmp_high = tmp_high['high'].dropna()\n",
    "\n",
    "    tmp_low = tmp['low'].resample(freq).ohlc()\n",
    "    tmp_low = tmp_low['low'].dropna()\n",
    "\n",
    "    tmp_close = tmp['close'].resample(freq).ohlc()\n",
    "    tmp_close = tmp_close['close'].dropna()\n",
    "\n",
    "    tmp_price = pd.concat([tmp_open, tmp_high, tmp_low, tmp_close], axis=1)\n",
    "    \n",
    "    # 处理成交量\n",
    "    tmp_volume = tmp['volume'].resample(freq).sum()\n",
    "    tmp_volume.dropna(inplace=True)\n",
    "    \n",
    "    return pd.concat([tmp_price, tmp_volume], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 open   close    high     low      volume trading_point\n",
      "trading_point                                                          \n",
      "2014-01-02     3.1274  3.2937  3.3148  3.1227  51073320.0    2014-01-02\n",
      "2014-01-03     3.2797  3.3406  3.3945  3.2633  61031636.0    2014-01-03\n",
      "2014-01-06     3.2797  3.2117  3.3265  3.1860  46161948.0    2014-01-06\n",
      "2014-01-07     3.1860  3.2235  3.2516  3.1860  24545424.0    2014-01-07\n",
      "2014-01-08     3.2281  3.3242  3.3382  3.2281  37178264.0    2014-01-08\n",
      "...               ...     ...     ...     ...         ...           ...\n",
      "2016-12-26     4.8251  4.9330  4.9428  4.7368  47045690.0    2016-12-26\n",
      "2016-12-27     5.0016  4.9526  5.0899  4.9330  79567159.0    2016-12-27\n",
      "2016-12-28     4.9232  4.8741  5.0016  4.8349  58147107.0    2016-12-28\n",
      "2016-12-29     4.8545  4.8251  4.8741  4.7859  31178446.0    2016-12-29\n",
      "2016-12-30     4.8251  4.8153  4.8545  4.7760  30835028.0    2016-12-30\n",
      "\n",
      "[733 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from Talib_calc import *\n",
    "\n",
    "tmp = fix_data('hs300.csv')\n",
    "\n",
    "# targets 1d 数据合成\n",
    "tmp_1d = High_2_Low(tmp, '1d')\n",
    "rolling = 88\n",
    "targets = tmp_1d\n",
    "targets['returns'] =  targets['close'].shift(-2) / targets['close'] - 1.0\n",
    "targets['upper_boundary']= targets.returns.rolling(rolling).mean() + 0.5 * targets.returns.rolling(rolling).std()\n",
    "targets['lower_boundary']= targets.returns.rolling(rolling).mean() - 0.5 * targets.returns.rolling(rolling).std()\n",
    "targets.dropna(inplace=True)\n",
    "targets['labels'] = 1\n",
    "targets.loc[targets['returns']>=targets['upper_boundary'], 'labels'] = 2\n",
    "targets.loc[targets['returns']<=targets['lower_boundary'], 'labels'] = 0\n",
    "\n",
    "# factors 1d 数据合成\n",
    "tmp_1d = High_2_Low(tmp, '1d')\n",
    "Index = tmp_1d.index\n",
    "High = tmp_1d.high.values\n",
    "Low = tmp_1d.low.values\n",
    "Close = tmp_1d.close.values\n",
    "Open = tmp_1d.open.values\n",
    "Volume = tmp_1d.volume.values\n",
    "factors = get_factors(Index, Open, Close, High, Low, Volume, rolling = 26, drop=True)\n",
    "\n",
    "factors = factors.loc[:targets.index[-1]]\n",
    "\n",
    "tmp_factors_1 = factors.iloc[:12]\n",
    "targets = targets.loc[tmp_factors_1.index[-1]:]\n",
    "\n",
    "gather_list = np.arange(factors.shape[0])[11:]\n",
    "\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 转换数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0ffb04e475f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdense_to_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "print(factors.shape)\n",
    "\n",
    "inputs = np.array(factors).reshape(-1, 1, factors.shape[1])\n",
    "\n",
    "def dense_to_one_hot(labels_dense):\n",
    "    \"\"\"标签 转换one hot 编码\n",
    "    输入labels_dense 必须为非负数\n",
    "    2016-11-21\n",
    "    \"\"\"\n",
    "    num_classes = len(np.unique(labels_dense)) # np.unique 去掉重复函数\n",
    "    raws_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(raws_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((raws_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot  \n",
    "\n",
    "targets = dense_to_one_hot(targets['labels'])\n",
    "targets = np.expand_dims(targets, axis=1)\n",
    "\n",
    "print(factors.shape[1])\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Classifier_PonderDNC_BasicLSTM_L3 import *\n",
    "\n",
    "op1 = Classifier_PonderDNC_BasicLSTM_L3(\n",
    "    inputs= inputs, \n",
    "    targets= targets, \n",
    "    gather_list= gather_list, \n",
    "    hidden_size= 50, \n",
    "    memory_size= 50, \n",
    "    pondering_coefficient= 1e-2, \n",
    "    learning_rate= 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1.fit(training_iters = 100,\n",
    "        display_step = 10,\n",
    "        save_path = \"model/ResidualPonderDNC_1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "op2 = Classifier_PonderDNC_BasicLSTM_L3(\n",
    "    inputs= inputs, \n",
    "    targets= targets, \n",
    "    gather_list= gather_list, \n",
    "    hidden_size= 50, \n",
    "    memory_size= 50, \n",
    "    pondering_coefficient= 1e-2, \n",
    "    learning_rate= 1e-3)\n",
    "\n",
    "op2.fit(training_iters = 100,\n",
    "        display_step = 10,\n",
    "        save_path = \"model/ResidualPonderDNC_1.ckpt\",\n",
    "        restore_path = \"model/ResidualPonderDNC_1.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "op3 = Classifier_PonderDNC_BasicLSTM_L3(\n",
    "    inputs= inputs, \n",
    "    targets= targets, \n",
    "    gather_list= gather_list, \n",
    "    hidden_size= 50, \n",
    "    memory_size= 50, \n",
    "    pondering_coefficient= 1e-2, \n",
    "    learning_rate= 1e-3)\n",
    "\n",
    "op3.fit(training_iters = 100,\n",
    "        display_step = 10,\n",
    "        save_path = \"model/ResidualPonderDNC_1.ckpt\",\n",
    "        restore_path = \"model/ResidualPonderDNC_1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "op4 = Classifier_PonderDNC_BasicLSTM_L3(\n",
    "    inputs= inputs, \n",
    "    targets= targets, \n",
    "    gather_list= gather_list, \n",
    "    hidden_size= 50, \n",
    "    memory_size= 50, \n",
    "    pondering_coefficient= 1e-2, \n",
    "    learning_rate= 1e-3)\n",
    "\n",
    "op4.fit(training_iters = 50,\n",
    "        display_step = 10,\n",
    "        save_path = \"model/ResidualPonderDNC_1.ckpt\",\n",
    "        restore_path = \"model/ResidualPonderDNC_1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "op5 = Classifier_PonderDNC_BasicLSTM_L3(\n",
    "    inputs= inputs, \n",
    "    targets= targets, \n",
    "    gather_list= gather_list, \n",
    "    hidden_size= 50, \n",
    "    memory_size= 50, \n",
    "    pondering_coefficient= 1e-1, \n",
    "    learning_rate= 1e-3)\n",
    "\n",
    "op5.fit(training_iters = 50,\n",
    "        display_step = 10,\n",
    "        save_path = \"model/ResidualPonderDNC_2.ckpt\",\n",
    "        restore_path = \"model/ResidualPonderDNC_1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "op6 = Classifier_PonderDNC_BasicLSTM_L3(\n",
    "    inputs= inputs, \n",
    "    targets= targets, \n",
    "    gather_list= gather_list, \n",
    "    hidden_size= 50, \n",
    "    memory_size= 50, \n",
    "    pondering_coefficient= 1e-1, \n",
    "    learning_rate= 1e-4)\n",
    "\n",
    "op6.fit(training_iters = 100,\n",
    "        display_step = 10,\n",
    "        save_path = \"model/ResidualPonderDNC_3.ckpt\",\n",
    "        restore_path = \"model/ResidualPonderDNC_2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "op7 = Classifier_PonderDNC_BasicLSTM_L3(\n",
    "    inputs= inputs, \n",
    "    targets= targets, \n",
    "    gather_list= gather_list, \n",
    "    hidden_size= 50, \n",
    "    memory_size= 50, \n",
    "    pondering_coefficient= 1e-1, \n",
    "    learning_rate= 1e-4)\n",
    "\n",
    "op7.fit(training_iters = 100,\n",
    "        display_step = 10,\n",
    "        save_path = \"model/ResidualPonderDNC_4.ckpt\",\n",
    "        restore_path = \"model/ResidualPonderDNC_3.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = op7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置回测框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rqalpha.api as rqa\n",
    "from rqalpha import run_func\n",
    "\n",
    "def init(context):\n",
    "    context.contract = '601933.XSHG'\n",
    "    context.BarSpan = 200\n",
    "    context.TransactionRate = '1d'\n",
    "    context.DataFields = ['datetime', 'open', 'close','high', 'low', 'volume']\n",
    "    context.DefineQuantity = 5 \n",
    "    context.func_get_factors = get_factors\n",
    "    context.model_classifier = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_bar(context, bar_dict):\n",
    "    \n",
    "    # 合约池代码 \n",
    "    contract = context.contract\n",
    "    #rqa.logger.info('------------------------------------')\n",
    "    #timepoint = rqa.history_bars(contract, 1, '1d', 'datetime')[0]  \n",
    "    #timepoint = pd.to_datetime(str(timepoint))\n",
    "    #timepoint = rqa.get_next_trading_date(timepoint)\n",
    "    #rqa.logger.info (timepoint)    \n",
    "    \n",
    "    # 获取合约报价\n",
    "    Quotes = rqa.history_bars(\n",
    "        order_book_id= contract, \n",
    "        bar_count= context.BarSpan, \n",
    "        frequency= context.TransactionRate,\n",
    "        fields= context.DataFields)\n",
    "    Quotes = pd.DataFrame(Quotes)\n",
    "    #print(Quotes)\n",
    "\n",
    "    # 计算技术分析指标\n",
    "    tmp_factors = context.func_get_factors(\n",
    "        index= pd.to_datetime(Quotes['datetime']), \n",
    "        Open= Quotes['open'].values, \n",
    "        Close= Quotes['close'].values, \n",
    "        High= Quotes['high'].values, \n",
    "        Low= Quotes['low'].values, \n",
    "        Volume=Quotes['volume'].values,\n",
    "        drop=True)   \n",
    "    inputs = np.expand_dims(np.array(tmp_factors), axis=1)    \n",
    "    \n",
    "    # 模型预测\n",
    "    probability, classification = context.model_classifier.pred(inputs)\n",
    "    flag = classification[-1][0]\n",
    "    rqa.logger.info(str(flag))\n",
    "    #print (flag)\n",
    "    \n",
    "    # 绘制估计概率\n",
    "    rqa.plot(\"估空概率\", probability[-1][0][0])\n",
    "    rqa.plot(\"振荡概率\", probability[-1][0][1])\n",
    "    rqa.plot(\"估多概率\", probability[-1][0][2])\n",
    "    \n",
    "    # 获取仓位\n",
    "    cur_position = context.portfolio.accounts['STOCK'].positions\n",
    "\n",
    "    # 卖出\n",
    "    if flag == 0:\n",
    "        rqa.logger.info ('沽空')\n",
    "        rqa.order_target_percent(contract, 0)            \n",
    "            \n",
    "    # 买入\n",
    "    if flag == 2:\n",
    "        rqa.logger.info ('沽多')\n",
    "        rqa.order_target_percent(contract, 1)      \n",
    "            \n",
    "    if flag == 1:\n",
    "        '''\n",
    "        rqa.logger.info ('振荡区间')\n",
    "        if tmp_sell_quantity > 0:\n",
    "            rqa.buy_close(contract, tmp_sell_quantity)\n",
    "            rqa.logger.info ('平空单')\n",
    "        if tmp_buy_quantity > 0:\n",
    "            rqa.sell_close(contract, tmp_buy_quantity)\n",
    "            rqa.logger.info ('平多单')\n",
    "        else:\n",
    "            rqa.logger.info ('空仓规避')\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_date = '2016-01-01'\n",
    "end_date = '2017-01-01'\n",
    "accounts = {'stock':1e5}\n",
    "\n",
    "config = {\n",
    "    'base':{'start_date':start_date, 'end_date':end_date, 'accounts':accounts},\n",
    "    'extra':{'log_level':'info'},\n",
    "    'mod':{'sys_analyser':{'enabled':True, 'plot':True}}\n",
    "}\n",
    "\n",
    "results = run_func(init=init, handle_bar=handle_bar, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_date = '2017-01-01'\n",
    "end_date = '2017-8-27'\n",
    "accounts = {'stock':1e5}\n",
    "\n",
    "config = {\n",
    "    'base':{'start_date':start_date, 'end_date':end_date, 'accounts':accounts},\n",
    "    'extra':{'log_level':'info'},\n",
    "    'mod':{'sys_analyser':{'enabled':True, 'plot':True}}\n",
    "}\n",
    "\n",
    "results = run_func(init=init, handle_bar=handle_bar, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
